import pytest\nfrom unittest.mock import Mock\nimport json\nimport time\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Any, Optional\nfrom llm_easy_tools.types import SimpleMessage, SimpleToolCall, SimpleFunction, SimpleChoice, SimpleCompletion\nfrom llm_easy_tools.processor import process_response, process_tool_call, ToolResult, process_one_tool_call\nfrom llm_easy_tools import LLMFunction\nfrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n\ndef mk_tool_call(name, args):\n    arguments = json.dumps(args)\n    return SimpleToolCall(id='A', function=SimpleFunction(name=name, arguments=arguments), type='function')\n\ndef mk_tool_call_json(name, args):\n    return SimpleToolCall(id='A', function=SimpleFunction(name=name, arguments=args), type='function')\n\ndef mk_chat_completion(tool_calls):\n    return SimpleCompletion(\n        id='A',\n        created=0,\n        model='gpt-3.5-turbo',\n        object='chat.completion',\n        choices=[\n            SimpleChoice(\n                finish_reason='stop',\n                index=0,\n                message=SimpleMessage(role='assistant', tool_calls=tool_calls))\n        ]\n    )\n\ndef test_process_methods():\n    class TestTool:\n        def tool_method(self, arg: int) -> str:\n            return f'executed tool_method with param: {arg}'\n\n        def no_output(self, arg: int):\n            pass\n\n        def failing_method(self, arg: int) -> str:\n            raise Exception('Some exception')\n\n    tool = TestTool()\n\n    tool_call = mk_tool_call(\